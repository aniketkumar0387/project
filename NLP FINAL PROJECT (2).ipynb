{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce922a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#L1=[10,20,36,36,2,3,3,69,10,20,25,20,36,10]\n",
    "#count=Counter(L1)\n",
    "#print(count.most_common(1))\n",
    "#print(count.most_common(2))\n",
    "#count.most_common(2)[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import googletrans\n",
    "from googletrans import Translator\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.util import ngrams\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import contractions\n",
    "import yake\n",
    "from rake_nltk import Rake\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from yellowbrick.cluster import SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2faaf3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0491108</td>\n",
       "      <td>product_es_0296024</td>\n",
       "      <td>reviewer_es_0999081</td>\n",
       "      <td>1</td>\n",
       "      <td>Nada bueno se me fue ka pantalla en menos de 8...</td>\n",
       "      <td>television Nevir</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_0869872</td>\n",
       "      <td>product_es_0922286</td>\n",
       "      <td>reviewer_es_0216771</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible, nos tuvimos que comprar otro porque ...</td>\n",
       "      <td>Dinero tirado a la basura con esta compra</td>\n",
       "      <td>es</td>\n",
       "      <td>electronics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    review_id          product_id          reviewer_id  stars  \\\n",
       "0  es_0491108  product_es_0296024  reviewer_es_0999081      1   \n",
       "1  es_0869872  product_es_0922286  reviewer_es_0216771      1   \n",
       "\n",
       "                                         review_body  \\\n",
       "0  Nada bueno se me fue ka pantalla en menos de 8...   \n",
       "1  Horrible, nos tuvimos que comprar otro porque ...   \n",
       "\n",
       "                                review_title language product_category  \n",
       "0                           television Nevir       es      electronics  \n",
       "1  Dinero tirado a la basura con esta compra       es      electronics  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('dataset_es_train.csv')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1626c4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ceda5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_title</th>\n",
       "      <th>language</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es_0565694</td>\n",
       "      <td>product_es_0752352</td>\n",
       "      <td>reviewer_es_0206726</td>\n",
       "      <td>2</td>\n",
       "      <td>Desde el primer día las puse y han funcionado ...</td>\n",
       "      <td>Han durado 1 año</td>\n",
       "      <td>es</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es_0777440</td>\n",
       "      <td>product_es_0578815</td>\n",
       "      <td>reviewer_es_0125595</td>\n",
       "      <td>3</td>\n",
       "      <td>Por el precio que tiene cumple las expectativas</td>\n",
       "      <td>Precio - calidad - bien</td>\n",
       "      <td>es</td>\n",
       "      <td>wireless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es_0004790</td>\n",
       "      <td>product_es_0445877</td>\n",
       "      <td>reviewer_es_0340121</td>\n",
       "      <td>4</td>\n",
       "      <td>Calidad y precio estupendo, venía todo muy bie...</td>\n",
       "      <td>Contenta</td>\n",
       "      <td>es</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es_0040618</td>\n",
       "      <td>product_es_0206868</td>\n",
       "      <td>reviewer_es_0659304</td>\n",
       "      <td>3</td>\n",
       "      <td>Son soportes algo endebles, pero para muñecas ...</td>\n",
       "      <td>Suficientes</td>\n",
       "      <td>es</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es_0252341</td>\n",
       "      <td>product_es_0323947</td>\n",
       "      <td>reviewer_es_0478834</td>\n",
       "      <td>4</td>\n",
       "      <td>Para windows hay que instalar el driver del CD...</td>\n",
       "      <td>Chip correcto</td>\n",
       "      <td>es</td>\n",
       "      <td>pc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>es_0646398</td>\n",
       "      <td>product_es_0426925</td>\n",
       "      <td>reviewer_es_0339032</td>\n",
       "      <td>4</td>\n",
       "      <td>El pedido se recibió pronto y correctamente. T...</td>\n",
       "      <td>Cumple lo esperado</td>\n",
       "      <td>es</td>\n",
       "      <td>home_improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>es_0361956</td>\n",
       "      <td>product_es_0537299</td>\n",
       "      <td>reviewer_es_0958798</td>\n",
       "      <td>1</td>\n",
       "      <td>No he recibido el paquete todavía! No sé si se...</td>\n",
       "      <td>Imposible valoración</td>\n",
       "      <td>es</td>\n",
       "      <td>toy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>es_0625797</td>\n",
       "      <td>product_es_0737551</td>\n",
       "      <td>reviewer_es_0184688</td>\n",
       "      <td>2</td>\n",
       "      <td>Me esperaba o tipo de calcetines .son finos no...</td>\n",
       "      <td>Son muy finos</td>\n",
       "      <td>es</td>\n",
       "      <td>apparel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>es_0477922</td>\n",
       "      <td>product_es_0915368</td>\n",
       "      <td>reviewer_es_0310537</td>\n",
       "      <td>5</td>\n",
       "      <td>Se trata de un pulsioximetro muy útil, funcion...</td>\n",
       "      <td>Práctico y cómodo</td>\n",
       "      <td>es</td>\n",
       "      <td>personal_care_appliances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>es_0776357</td>\n",
       "      <td>product_es_0656536</td>\n",
       "      <td>reviewer_es_0862838</td>\n",
       "      <td>4</td>\n",
       "      <td>La zona del pecho es más pequeña que la de la ...</td>\n",
       "      <td>.</td>\n",
       "      <td>es</td>\n",
       "      <td>pet_products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_id          product_id          reviewer_id  stars  \\\n",
       "0   es_0565694  product_es_0752352  reviewer_es_0206726      2   \n",
       "1   es_0777440  product_es_0578815  reviewer_es_0125595      3   \n",
       "2   es_0004790  product_es_0445877  reviewer_es_0340121      4   \n",
       "3   es_0040618  product_es_0206868  reviewer_es_0659304      3   \n",
       "4   es_0252341  product_es_0323947  reviewer_es_0478834      4   \n",
       "..         ...                 ...                  ...    ...   \n",
       "95  es_0646398  product_es_0426925  reviewer_es_0339032      4   \n",
       "96  es_0361956  product_es_0537299  reviewer_es_0958798      1   \n",
       "97  es_0625797  product_es_0737551  reviewer_es_0184688      2   \n",
       "98  es_0477922  product_es_0915368  reviewer_es_0310537      5   \n",
       "99  es_0776357  product_es_0656536  reviewer_es_0862838      4   \n",
       "\n",
       "                                          review_body  \\\n",
       "0   Desde el primer día las puse y han funcionado ...   \n",
       "1     Por el precio que tiene cumple las expectativas   \n",
       "2   Calidad y precio estupendo, venía todo muy bie...   \n",
       "3   Son soportes algo endebles, pero para muñecas ...   \n",
       "4   Para windows hay que instalar el driver del CD...   \n",
       "..                                                ...   \n",
       "95  El pedido se recibió pronto y correctamente. T...   \n",
       "96  No he recibido el paquete todavía! No sé si se...   \n",
       "97  Me esperaba o tipo de calcetines .son finos no...   \n",
       "98  Se trata de un pulsioximetro muy útil, funcion...   \n",
       "99  La zona del pecho es más pequeña que la de la ...   \n",
       "\n",
       "               review_title language          product_category  \n",
       "0          Han durado 1 año       es                      home  \n",
       "1   Precio - calidad - bien       es                  wireless  \n",
       "2                  Contenta       es                       toy  \n",
       "3               Suficientes       es                       toy  \n",
       "4             Chip correcto       es                        pc  \n",
       "..                      ...      ...                       ...  \n",
       "95       Cumple lo esperado       es          home_improvement  \n",
       "96     Imposible valoración       es                       toy  \n",
       "97            Son muy finos       es                   apparel  \n",
       "98        Práctico y cómodo       es  personal_care_appliances  \n",
       "99                        .       es              pet_products  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = data.sample(100)\n",
    "sample.reset_index(drop=True,inplace=True)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6141d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Desde el primer día las puse y han funcionado ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Por el precio que tiene cumple las expectativas</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calidad y precio estupendo, venía todo muy bie...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Son soportes algo endebles, pero para muñecas ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Para windows hay que instalar el driver del CD...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>El pedido se recibió pronto y correctamente. T...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>No he recibido el paquete todavía! No sé si se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Me esperaba o tipo de calcetines .son finos no...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Se trata de un pulsioximetro muy útil, funcion...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>La zona del pecho es más pequeña que la de la ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          review_body  stars\n",
       "0   Desde el primer día las puse y han funcionado ...      2\n",
       "1     Por el precio que tiene cumple las expectativas      3\n",
       "2   Calidad y precio estupendo, venía todo muy bie...      4\n",
       "3   Son soportes algo endebles, pero para muñecas ...      3\n",
       "4   Para windows hay que instalar el driver del CD...      4\n",
       "..                                                ...    ...\n",
       "95  El pedido se recibió pronto y correctamente. T...      4\n",
       "96  No he recibido el paquete todavía! No sé si se...      1\n",
       "97  Me esperaba o tipo de calcetines .son finos no...      2\n",
       "98  Se trata de un pulsioximetro muy útil, funcion...      5\n",
       "99  La zona del pecho es más pequeña que la de la ...      4\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=sample[['review_body','stars']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193f7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language detection\n",
    "def lang_detect(data):\n",
    "    lang = detect(data)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d221ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por el precio que tiene cumple las expectativas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['review_body'][1])\n",
    "lang_detect(df['review_body'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d52d069",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreview_body\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang_detect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mlang_detect\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlang_detect\u001b[39m(data):\n\u001b[1;32m----> 3\u001b[0m     lang \u001b[38;5;241m=\u001b[39m \u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lang\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector_factory.py:130\u001b[0m, in \u001b[0;36mdetect\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    128\u001b[0m detector \u001b[38;5;241m=\u001b[39m _factory\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[0;32m    129\u001b[0m detector\u001b[38;5;241m.\u001b[39mappend(text)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector.py:136\u001b[0m, in \u001b[0;36mDetector.detect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdetect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;124;03m'''Detect language of the target text and return the language name\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    which has the highest probability.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_probabilities\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m probabilities:\n\u001b[0;32m    138\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m probabilities[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlang\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector.py:143\u001b[0m, in \u001b[0;36mDetector.get_probabilities\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probabilities\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_detect_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sort_probability(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangprob)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector.py:163\u001b[0m, in \u001b[0;36mDetector._detect_block\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_lang_prob(prob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(ngrams), alpha)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_normalize_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mCONV_THRESHOLD \u001b[38;5;129;01mor\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mITERATION_LIMIT:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\langdetect\\detector.py:231\u001b[0m, in \u001b[0;36mDetector._normalize_prob\u001b[1;34m(self, prob)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m maxp \u001b[38;5;241m<\u001b[39m p:\n\u001b[0;32m    230\u001b[0m         maxp \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 231\u001b[0m     prob[i] \u001b[38;5;241m=\u001b[39m p\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maxp\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df['language']=df.review_body.apply(lang_detect)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ed68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c27b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247e1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language translation\n",
    "\n",
    "def lang_trans(data):\n",
    "    translor = Translator()\n",
    "    translated_text = translor.translate(data)\n",
    "    return translated_text.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e98e804",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.review_body[2])\n",
    "lang_trans(df.review_body[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41971e32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['translated_review']= df.review_body.apply(lang_trans)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c735e27",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_text(data):\n",
    "    expanded_text=contractions.fix(data)\n",
    "    return expanded_text\n",
    "\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('nor')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def clean_data(data):\n",
    "    tokens=word_tokenize(data)\n",
    "    clean_text=[word.lower() for word in tokens if (word not in punctuation) and (word.lower() not in stopword_list) and (len(word)>2) and (word.isalpha())]\n",
    "    return ' '.join(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = df.translated_review.apply(expand_text)\n",
    "clean_text = clean_text.apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe513ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e66773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_text[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.translated_review[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d907893",
   "metadata": {},
   "source": [
    "## 1.Ngram Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8977eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_extractor(data,ngram_range):\n",
    "    tokens=word_tokenize(data)\n",
    "    ngram= ngrams(tokens,ngram_range)\n",
    "    ngram_list1=[]\n",
    "    \n",
    "    for ngram1 in ngram:\n",
    "        ngram_list1.append(' '.join(ngram1))\n",
    "    return ngram_list1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd2cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unigrams = clean_text.apply(lambda x:ngram_extractor(x,1))\n",
    "final_unigram=[]\n",
    "\n",
    "for unigram in list_unigrams:\n",
    "    final_unigram.extend(unigram)\n",
    "cnt=Counter(final_unigram).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa947e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=Counter(final_unigram).most_common(25)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e28db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_bigrams = clean_text.apply(lambda x:ngram_extractor(x,2))\n",
    "final_bigram=[]\n",
    "\n",
    "for bigram in list_bigrams:\n",
    "    final_bigram.extend(bigram)\n",
    "cnt2=Counter(final_bigram).most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28036aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt2=Counter(final_bigram).most_common(25)\n",
    "cnt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_trigrams = clean_text.apply(lambda x:ngram_extractor(x,3))\n",
    "final_trigram=[]\n",
    "\n",
    "for trigram in list_trigrams:\n",
    "    final_trigram.extend(trigram)\n",
    "cnt3=Counter(final_trigram).most_common(25)\n",
    "cnt3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b1c0a",
   "metadata": {},
   "source": [
    "## 2.Wordcloud generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordcloud(data,column):\n",
    "    df_= data[column].str.cat(sep=' ')\n",
    "    text =' '.join([word for word in df_.split()])\n",
    "    wordcloud = WordCloud(width=700 ,height=500 ,background_color='white').generate(text)\n",
    "    plt.figure(figsize = (20,50))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "  \n",
    "wordcloud(df,'translated_review')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970ed6b",
   "metadata": {},
   "source": [
    "## 3.Keyphrase extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343f620",
   "metadata": {},
   "source": [
    "### YAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f75a2c",
   "metadata": {},
   "source": [
    "Syntax\n",
    "\n",
    "\n",
    "i/p :-\n",
    "\n",
    "from yake import KeywordExtractor\n",
    "\n",
    "text = \"This is a sample text for testing YAKE keyword extraction function in Python\"\n",
    "kw_extractor = KeywordExtractor()\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "\n",
    "print(keywords)\n",
    "\n",
    "o/p\n",
    "\n",
    "[('YAKE keyword extraction function', 0.1560054334917623), ('Python', 0.1686488256612227), ('sample text', 0.2113766985092226), ('testing', 0.2842842231669544), ('function', 0.30201086698352487), ('keyword extraction', 0.34850109522579016)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yake_extracter(data):\n",
    "    keyword_extractor = yake.KeywordExtractor()\n",
    "    keywords = keyword_extractor.extract_keywords (data)\n",
    "    keyword_list = []\n",
    "    \n",
    "    for kw in keywords:\n",
    "        keyword_list.append(kw[0])\n",
    "    return keyword_list\n",
    "\n",
    "keywords=df.translated_review.apply(yake_extracter)\n",
    "all_keywords = []\n",
    "\n",
    "for kw in keywords:\n",
    "    all_keywords.extend(kw)\n",
    "    \n",
    "cnt_kw=Counter(all_keywords).most_common(1500)\n",
    "cnt_kw\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8728725",
   "metadata": {},
   "source": [
    "### RAKE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234193d",
   "metadata": {},
   "source": [
    "Syntax\n",
    "\n",
    "\n",
    "i/p :-\n",
    "\n",
    "from rake_nltk import Rake\n",
    "\n",
    "text = \"This is a sample text for testing RAKE keyword extraction function in Python\"\n",
    "r = Rake()\n",
    "r.extract_keywords_from_text(text)\n",
    "keywords = r.get_ranked_phrases()\n",
    "\n",
    "print(keywords)\n",
    "\n",
    "o/p :- \n",
    "\n",
    "['testing rake keyword extraction function', 'sample text', 'python', 'keyword extraction function', 'rake keyword extraction function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd317dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rake_extracter(data):\n",
    "    keyword_extractor = Rake()\n",
    "    keyword_extractor.extract_keywords_from_text(data)\n",
    "    return keyword_extractor.get_ranked_phrases()\n",
    "\n",
    "rake_keywords=df.translated_review.apply(rake_extracter)\n",
    "all_keywords = []\n",
    "\n",
    "for kw_rake in rake_keywords:\n",
    "    all_keywords.extend(kw_rake)\n",
    "    \n",
    "cnt_kw_rake=Counter(all_keywords).most_common(1500)\n",
    "cnt_kw_rake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f3055",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7186ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces, new lines\n",
    "def remove_spaces(data):\n",
    "    clean_text= data.replace('\\\\n','').replace('\\t','').replace('\\\\','')\n",
    "    return clean_text\n",
    "\n",
    "#contraction mapping\n",
    "def expand_text(data):\n",
    "    expanded_text=contractions.fix(data)\n",
    "    return expanded_text\n",
    "\n",
    "# handling accented characters\n",
    "def handling_accented(data):\n",
    "    fixed_text=unidecode(data)\n",
    "    return fixed_text\n",
    "\n",
    "#cleaning\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('nor')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "def clean_data(data):\n",
    "    tokens=word_tokenize(data)\n",
    "    clean_text=[word.lower() for word in tokens if (word not in punctuation) and (word.lower() not in stopword_list) and (len(word)>2) and (word.isalpha())]\n",
    "    return ' '.join(clean_text)\n",
    "\n",
    "#autocorrect\n",
    "#def autocorrection(data):\n",
    "    #spell=Speller(lang='en')\n",
    "    #corrected_text=spell(data)\n",
    "    #return corrected_text\n",
    "\n",
    "# lemmatization\n",
    "\n",
    "def lemmatization(data):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    final_data = []\n",
    "    \n",
    "    for word in data:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        final_data.append(lemmatized_word)\n",
    "        return \" \".join(final_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[(df.stars<3)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f028da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_train= df.translated_review.apply(remove_spaces)\n",
    "\n",
    "clean_text_train= clean_text_train.apply(expand_text)\n",
    "\n",
    "clean_text_train= clean_text_train.apply(handling_accented)\n",
    "\n",
    "clean_text_train= clean_text_train.apply(clean_data)\n",
    "\n",
    "#clean_text_train= clean_text_train.apply(lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b7a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af3232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text vectorizer\n",
    "\n",
    "#Count vectorizer\n",
    "\n",
    "count_vec= CountVectorizer()\n",
    "bow= count_vec.fit_transform(clean_text_train).A\n",
    "pd.DataFrame(bow,columns= count_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf vectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "tfidf = tfidf_vec.fit_transform(clean_text_train).A\n",
    "pd.DataFrame(tfidf,columns= tfidf_vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_text_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5519b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec\n",
    "\n",
    "sent=clean_text_train.tolist()\n",
    "splitted_text = [x.split() for x in sent]\n",
    "print(splitted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14586aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_2vec_model= Word2Vec(splitted_text,min_count=2, window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba981ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "word_2vec_model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af768692",
   "metadata": {},
   "source": [
    "#numeric format of document\n",
    "\n",
    "w1=vect_1\n",
    "w2=vect_2\n",
    "w3=vect_3\n",
    "\n",
    "review_1=[w1,w2,w3]\n",
    "review_1_vect=avg(vect_1,vect_2,vect_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40484e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(list_of_docs,model):\n",
    "    feature=[]\n",
    "    \n",
    "    for rew in list_of_docs:\n",
    "        zero_vector= np.zeros(model.vector_size)\n",
    "        vector=[]\n",
    "        for word in rew:\n",
    "            if word in model.wv:\n",
    "                try:\n",
    "                    vector.append(model.wv[word]) # model.wv['bad']\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                    \n",
    "        if vector:\n",
    "            vector=np.asarray(vector)\n",
    "            avg_vec=vector.mean(axis=0)\n",
    "            feature.append(avg_vec)\n",
    "            \n",
    "        else:\n",
    "            feature.append(zero_vector)\n",
    "    return feature\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9db0db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_docs=vectorizer(splitted_text,word_2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f5507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857daf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb=np.array(vectorized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f73953",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ad65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_kmeans (clusters,data):\n",
    "    kmeans_model=KMeans(n_clusters=clusters)\n",
    "    y_pred=kmeans_model.fit_predict(data)\n",
    "    return kmeans_model, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8701bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans_count_vectorizer\n",
    "kmeans_model_count, count_pred = build_kmeans (3,bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4b1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(count_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ab4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans_tfidf_vectorizer\n",
    "kmeans_model_tfidf, tfidf_pred = build_kmeans (3,tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c95429",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans_word2vec_vectorizer\n",
    "kmeans_model_word2vec, word2vec_pred = build_kmeans (3,x_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f5eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4e4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'silhouette score with kmeans-count : {silhouette_score(bow, count_pred)}')\n",
    "\n",
    "print(f'silhouette score with kmeans-tfidf : {silhouette_score(tfidf, tfidf_pred)}')\n",
    "\n",
    "print(f'silhouette score with kmeans-word2vec : {silhouette_score(x_emb, word2vec_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_silhouette (data,model,title):\n",
    "    visualizer= SilhouetteVisualizer(model, colors='yellowbrick')\n",
    "    visualizer.fit(data)\n",
    "    plt.title(f'Silhouette visualizer for {title}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette (bow, kmeans_model_count,'kmeans_count Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette (tfidf, kmeans_model_tfidf,'kmeans_tfidf Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e76883",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_silhouette (x_emb, kmeans_model_word2vec,'kmeans_word2vec Vectorizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b032c",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90549f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target']=word2vec_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e61eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceef14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce15071",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df.translated_review,df.Target,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1620b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125b8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "count_mnb = MultinomialNB()\n",
    "count_mnb.fit(x_train,y_train)\n",
    "predict_count=count_mnb.predict(clean_text_test)\n",
    "accuracy_count=accuracy_score(y_test,predict_count)*100\n",
    "accuracy_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b9648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
